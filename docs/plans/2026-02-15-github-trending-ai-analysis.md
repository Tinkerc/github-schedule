# GitHub Trending AI æ¯æ—¥åˆ†æ - å®æ–½è®¡åˆ’

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**ç›®æ ‡ï¼š** åˆ›å»ºç‹¬ç«‹çš„ GitHub Trending åˆ†æè„šæœ¬ï¼Œæ¯æ—¥è‡ªåŠ¨è·å–å‰ 25 ä¸ªçƒ­é—¨é¡¹ç›®ï¼Œä½¿ç”¨ GLM-4.7 æ¨¡å‹ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š

**æ¶æ„ï¼š** ä¸‰å±‚æ¶æ„ - æ•°æ®è·å–å±‚ï¼ˆçˆ¬è™«ï¼‰â†’ AI åˆ†æå±‚ï¼ˆGLM-4.7 APIï¼‰â†’ æŠ¥å‘Šç”Ÿæˆå±‚ï¼ˆMarkdownï¼‰ã€‚ä½¿ç”¨ç‹¬ç«‹ GitHub Actions workflow æ¯æ—¥è‡ªåŠ¨æ‰§è¡Œ

**æŠ€æœ¯æ ˆï¼š** Python 3.8, requests, pyquery, GLM-4.7 API

---

## Task 1: åˆ›å»º Prompt æ¨¡å—

**æ–‡ä»¶ï¼š**
- åˆ›å»º: `script/prompts/trending_prompts.py`

**æ­¥éª¤ 1: åˆ›å»º prompt æ¨¡å—åŸºç¡€ç»“æ„**

åˆ›å»ºæ–‡ä»¶ `script/prompts/trending_prompts.py`ï¼š

```python
# coding:utf-8
"""GitHub Trending AI åˆ†æçš„ Prompt æ¨¡æ¿"""

def get_batch_analysis_prompt(projects):
    """
    ç”Ÿæˆæ‰¹é‡åˆ†æé¡¹ç›®è¯¦æƒ…çš„ prompt

    Args:
        projects: list[dict], é¡¹ç›®åˆ—è¡¨ï¼Œæ¯ä¸ªé¡¹ç›®åŒ…å« name, description, url, stars, language, stars_today

    Returns:
        str: AI åˆ†æçš„ prompt
    """
    projects_text = ""
    for i, p in enumerate(projects, 1):
        projects_text += f"""
{i}. {p.get('name', 'Unknown')}
   æè¿°: {p.get('description', 'æš‚æ— æè¿°')}
   è¯­è¨€: {p.get('language', 'æœªçŸ¥')}
   æ˜Ÿæ ‡: {p.get('stars', 'N/A')} (ä»Šæ—¥ +{p.get('stars_today', 'N/A')})
   é“¾æ¥: {p.get('url', '')}
"""

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æå¼€æºé¡¹ç›®çš„æŠ€æœ¯ä»·å€¼å’Œå®ç”¨ä»·å€¼ã€‚

è¯·åˆ†æä»¥ä¸‹ {len(projects)} ä¸ª GitHub Trending é¡¹ç›®ï¼Œå¯¹æ¯ä¸ªé¡¹ç›®æä¾›è¯¦ç»†åˆ†æã€‚

é¡¹ç›®åˆ—è¡¨ï¼š
{projects_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "projects": [
        {{
            "name": "é¡¹ç›®åç§°",
            "core_functionality": "æ ¸å¿ƒåŠŸèƒ½ï¼ˆ1-2å¥è¯ï¼‰",
            "use_cases": "é€‚ç”¨åœºæ™¯ï¼ˆ3-4ä¸ªè¦ç‚¹ï¼Œç”¨æ¢è¡Œç¬¦åˆ†éš”ï¼‰",
            "tech_stack": "æŠ€æœ¯æ ˆï¼ˆå…³é”®ä¾èµ–/æ¡†æ¶ï¼‰",
            "tech_highlights": "æŠ€æœ¯äº®ç‚¹ï¼ˆ2-3ä¸ªè¦ç‚¹ï¼Œç”¨æ¢è¡Œç¬¦åˆ†éš”ï¼‰",
            "learning_value": "å­¦ä¹ ä»·å€¼ï¼ˆ1-2å¥è¯ï¼‰"
        }}
    ]
}}

æ³¨æ„ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—
2. core_functionality ç®€æ´æ˜äº†ï¼Œè¯´æ˜é¡¹ç›®åšä»€ä¹ˆ
3. use_cases è¦å…·ä½“ï¼Œè¯´æ˜åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹ä½¿ç”¨
4. tech_stack åˆ—å‡ºå…³é”®æŠ€æœ¯å’Œæ¡†æ¶
5. tech_highlights çªå‡ºæŠ€æœ¯åˆ›æ–°ç‚¹
6. learning_value è¯´æ˜å¼€å‘è€…èƒ½å­¦åˆ°ä»€ä¹ˆ
"""

    return prompt


def get_trend_summary_prompt(analyses):
    """
    ç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆå’Œçƒ­é—¨é¢†åŸŸåˆ†æçš„ prompt

    Args:
        analyses: dict, åŒ…å«æ‰€æœ‰é¡¹ç›®çš„åˆ†æç»“æœ

    Returns:
        str: AI åˆ†æçš„ prompt
    """
    projects_info = ""
    for p in analyses.get('projects', []):
        projects_info += f"""
- {p.get('name', 'Unknown')}: {p.get('core_functionality', '')}
  æŠ€æœ¯æ ˆ: {p.get('tech_stack', 'æœªçŸ¥')}
  æŠ€æœ¯äº®ç‚¹: {p.get('tech_highlights', '')}
"""

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æå¸ˆï¼Œæ“…é•¿å‘ç°æŠ€æœ¯å‘å±•åŠ¨å‘ã€‚

åŸºäºä»¥ä¸‹ {len(analyses.get('projects', []))} ä¸ªé¡¹ç›®çš„åˆ†æç»“æœï¼Œç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆå’Œçƒ­é—¨é¢†åŸŸåˆ†æã€‚

é¡¹ç›®åˆ†æï¼š
{projects_info}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼š
{{
    "trend_overview": "ä»Šæ—¥è¶‹åŠ¿æ¦‚è§ˆï¼ˆ3-5å¥è¯ï¼Œæè¿°æ•´ä½“æŠ€æœ¯è¶‹åŠ¿ç‰¹ç‚¹ã€åˆ›æ–°æ–¹å‘ã€çƒ­é—¨è¯é¢˜ç­‰ï¼‰",
    "hot_domains": [
        {{
            "domain": "é¢†åŸŸåç§°ï¼ˆå¦‚ AI/LLMã€Web3ã€DevOps ç­‰ï¼‰",
            "reason": "çƒ­é—¨åŸå› ï¼ˆ2-3å¥è¯ï¼‰",
            "projects": ["ç›¸å…³é¡¹ç›®åç§°1", "ç›¸å…³é¡¹ç›®åç§°2"]
        }}
    ]
}}

æ³¨æ„ï¼š
1. å¿…é¡»è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼
2. trend_overview è¦å®è§‚æè¿°æ•´ä½“è¶‹åŠ¿
3. hot_domains æå– 3-5 ä¸ªçƒ­é—¨é¢†åŸŸ
4. æ¯ä¸ªé¢†åŸŸè¦è¯´æ˜ä¸ºä»€ä¹ˆçƒ­é—¨ï¼Œå¹¶åˆ—å‡ºç›¸å…³é¡¹ç›®
"""

    return prompt
```

**æ­¥éª¤ 2: æäº¤åŸºç¡€ç»“æ„**

```bash
git add script/prompts/trending_prompts.py
git commit -m "feat: add trending analysis prompt module"
```

---

## Task 2: åˆ›å»ºçˆ¬è™«ç±»

**æ–‡ä»¶ï¼š**
- åˆ›å»º: `script/github-trending-ai-analysis.py`ï¼ˆåˆ›å»ºæ–‡ä»¶ï¼ŒåŒ…å« GitHubTrendingScraper ç±»ï¼‰

**æ­¥éª¤ 1: åˆ›å»ºä¸»è„šæœ¬æ–‡ä»¶å’Œçˆ¬è™«ç±»**

åˆ›å»ºæ–‡ä»¶ `script/github-trending-ai-analysis.py`ï¼š

```python
# coding:utf-8

import datetime
import os
import time
import codecs
import requests
import logging
import json
from pyquery import PyQuery as pq

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class GitHubTrendingScraper:
    """GitHub Trending çˆ¬è™«"""

    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; rv:11.0) Gecko/20100101 Firefox/11.0',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Encoding': 'gzip,deflate,sdch',
            'Accept-Language': 'zh-CN,zh;q=0.8'
        }

    def scrape_trending(self, language=''):
        """
        çˆ¬å– GitHub Trending é¡¹ç›®

        Args:
            language: str, ç¼–ç¨‹è¯­è¨€ï¼ˆç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ‰€æœ‰è¯­è¨€ï¼‰

        Returns:
            list[dict]: é¡¹ç›®åˆ—è¡¨
        """
        url = f'https://github.com/trending/{language}' if language else 'https://github.com/trending'

        for attempt in range(3):
            try:
                logger.info(f"æ­£åœ¨çˆ¬å– GitHub Trending: {url}")
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()

                doc = pq(response.content)
                items = doc('div.Box article.Box-row')

                projects = []
                for item in items:
                    i = pq(item)
                    title_elem = i(".lh-condensed a")
                    if not title_elem:
                        continue

                    title = title_elem.text()
                    url_path = title_elem.attr("href")
                    description = i("p.col-9").text().strip()

                    # è·å–æ˜Ÿæ ‡æ•°
                    stars_elem = i("a[href*='/stargazers']")
                    stars_text = stars_elem.text().strip() if stars_elem else "0"

                    # è·å–ä»Šæ—¥å¢é•¿æ˜Ÿæ ‡
                    today_stars_elem = i("span.d-inline-block")
                    today_stars_text = today_stars_elem.text().strip() if today_stars_elem else "0"

                    # è·å–è¯­è¨€
                    language_elem = i("span[itemprop='programmingLanguage']")
                    language_text = language_elem.text().strip() if language_elem else "æœªçŸ¥"

                    projects.append({
                        "name": title,
                        "description": description or "æš‚æ— æè¿°",
                        "url": f"https://github.com{url_path}",
                        "stars": stars_text,
                        "language": language_text,
                        "stars_today": today_stars_text.replace("stars today", "").strip()
                    })

                logger.info(f"æˆåŠŸçˆ¬å– {len(projects)} ä¸ªé¡¹ç›®")
                return projects

            except requests.exceptions.RequestException as e:
                logger.warning(f"è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/3): {str(e)}")
                if attempt < 2:
                    time.sleep(30)
                else:
                    raise

        return []

    def scrape_all_languages(self):
        """
        çˆ¬å–æ‰€æœ‰è¯­è¨€çš„ trending é¡¹ç›®ï¼ˆåªçˆ¬å–ä¸»é¡µé¢ï¼‰

        Returns:
            list[dict]: é¡¹ç›®åˆ—è¡¨ï¼ˆæœ€å¤š 25 ä¸ªï¼‰
        """
        projects = self.scrape_trending('')
        return projects[:25]  # é™åˆ¶ 25 ä¸ª
```

**æ­¥éª¤ 2: æµ‹è¯•çˆ¬è™«ç±»**

è¿è¡Œä»¥ä¸‹æµ‹è¯•ä»£ç ï¼š

```python
if __name__ == '__main__':
    scraper = GitHubTrendingScraper()
    projects = scraper.scrape_all_languages()
    print(f"çˆ¬å–åˆ° {len(projects)} ä¸ªé¡¹ç›®")
    for p in projects[:3]:
        print(f"- {p['name']}: {p['description'][:50]}...")
```

è¿è¡Œï¼š`python script/github-trending-ai-analysis.py`

é¢„æœŸè¾“å‡ºï¼š
```
[2026-02-15 XX:XX:XX] INFO: æ­£åœ¨çˆ¬å– GitHub Trending: https://github.com/trending
[2026-02-15 XX:XX:XX] INFO: æˆåŠŸçˆ¬å– 25 ä¸ªé¡¹ç›®
çˆ¬å–åˆ° 25 ä¸ªé¡¹ç›®
- é¡¹ç›®1: æè¿°...
- é¡¹ç›®2: æè¿°...
- é¡¹ç›®3: æè¿°...
```

**æ­¥éª¤ 3: æäº¤çˆ¬è™«ç±»**

```bash
git add script/github-trending-ai-analysis.py
git commit -m "feat: add GitHub Trending scraper class"
```

---

## Task 3: åˆ›å»º AI åˆ†æç±»

**æ–‡ä»¶ï¼š**
- ä¿®æ”¹: `script/github-trending-ai-analysis.py`ï¼ˆæ·»åŠ  GLMAnalyzer ç±»ï¼‰

**æ­¥éª¤ 1: æ·»åŠ  AI åˆ†æç±»**

åœ¨æ–‡ä»¶ `script/github-trending-ai-analysis.py` ä¸­æ·»åŠ  GLMAnalyzer ç±»ï¼ˆæ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾ï¼Œ`if __name__` ä¹‹å‰ï¼‰ï¼š

```python
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'prompts'))
from trending_prompts import get_batch_analysis_prompt, get_trend_summary_prompt


class GLMAnalyzer:
    """GLM-4.7 AI åˆ†æå™¨"""

    def __init__(self):
        self.api_key = os.environ.get('BIGMODEL_API_KEY')
        if not self.api_key:
            raise ValueError("ç¯å¢ƒå˜é‡ BIGMODEL_API_KEY æœªè®¾ç½®")

        self.api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        self.headers = {
            "Accept": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    def _call_api(self, prompt):
        """
        è°ƒç”¨ GLM-4.7 API

        Args:
            prompt: str, ç”¨æˆ· prompt

        Returns:
            dict: API è¿”å›çš„ JSON æ•°æ®
        """
        payload = {
            "model": "glm-4.7",
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åˆ†æå¸ˆï¼Œè¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 8000
        }

        for attempt in range(3):
            try:
                logger.info(f"æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• {attempt + 1}/3)")
                response = requests.post(
                    self.api_url,
                    headers=self.headers,
                    json=payload,
                    timeout=60
                )
                response.raise_for_status()

                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content']
                    logger.info("API è°ƒç”¨æˆåŠŸ")
                    return content
                else:
                    logger.error(f"API è¿”å›æ ¼å¼é”™è¯¯: {result}")
                    raise ValueError("Invalid API response")

            except requests.exceptions.RequestException as e:
                logger.warning(f"API è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/3): {str(e)}")
                if attempt < 2:
                    time.sleep(10)
                else:
                    raise

    def analyze_projects(self, projects):
        """
        æ‰¹é‡åˆ†æé¡¹ç›®

        Args:
            projects: list[dict], é¡¹ç›®åˆ—è¡¨

        Returns:
            dict: åˆ†æç»“æœ
        """
        prompt = get_batch_analysis_prompt(projects)
        response = self._call_api(prompt)

        # è§£æ JSON
        try:
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith('```json'):
                response = response[7:]
            if response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]
            response = response.strip()

            result = json.loads(response)
            if 'projects' not in result:
                raise ValueError("Response missing 'projects' field")

            logger.info(f"æˆåŠŸåˆ†æ {len(result['projects'])} ä¸ªé¡¹ç›®")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {str(e)}")
            logger.error(f"åŸå§‹å“åº”: {response[:500]}")
            raise

    def generate_trend_summary(self, analyses):
        """
        ç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆ

        Args:
            analyses: dict, é¡¹ç›®åˆ†æç»“æœ

        Returns:
            dict: è¶‹åŠ¿åˆ†æç»“æœ
        """
        prompt = get_trend_summary_prompt(analyses)
        response = self._call_api(prompt)

        # è§£æ JSON
        try:
            response = response.strip()
            if response.startswith('```json'):
                response = response[7:]
            if response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]
            response = response.strip()

            result = json.loads(response)
            if 'trend_overview' not in result:
                raise ValueError("Response missing 'trend_overview' field")

            logger.info("æˆåŠŸç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆ")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {str(e)}")
            logger.error(f"åŸå§‹å“åº”: {response[:500]}")
            raise
```

**æ­¥éª¤ 2: æµ‹è¯• AI åˆ†æç±»**

åœ¨ `if __name__ == '__main__':` éƒ¨åˆ†æ·»åŠ æµ‹è¯•ä»£ç ï¼š

```python
if __name__ == '__main__':
    # æµ‹è¯• AI åˆ†æ
    scraper = GitHubTrendingScraper()
    projects = scraper.scrape_all_languages()[:5]  # å…ˆæµ‹è¯• 5 ä¸ª

    analyzer = GLMAnalyzer()
    analyses = analyzer.analyze_projects(projects)
    print(f"åˆ†æç»“æœ: {json.dumps(analyses, ensure_ascii=False, indent=2)}")
```

è¿è¡Œï¼š`BIGMODEL_API_KEY=your_key python script/github-trending-ai-analysis.py`

é¢„æœŸè¾“å‡ºï¼š
```
[2026-02-15 XX:XX:XX] INFO: æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• 1/3)
[2026-02-15 XX:XX:XX] INFO: API è°ƒç”¨æˆåŠŸ
[2026-02-15 XX:XX:XX] INFO: æˆåŠŸåˆ†æ 5 ä¸ªé¡¹ç›®
åˆ†æç»“æœ: {
  "projects": [...]
}
```

**æ­¥éª¤ 3: æäº¤ AI åˆ†æç±»**

```bash
git add script/github-trending-ai-analysis.py
git commit -m "feat: add GLM-4.7 analyzer class"
```

---

## Task 4: åˆ›å»ºæŠ¥å‘Šç”Ÿæˆç±»

**æ–‡ä»¶ï¼š**
- ä¿®æ”¹: `script/github-trending-ai-analysis.py`ï¼ˆæ·»åŠ  MarkdownReportGenerator ç±»ï¼‰

**æ­¥éª¤ 1: æ·»åŠ æŠ¥å‘Šç”Ÿæˆç±»**

åœ¨æ–‡ä»¶ `script/github-trending-ai-analysis.py` ä¸­æ·»åŠ  MarkdownReportGenerator ç±»ï¼ˆæ·»åŠ åˆ° GLMAnalyzer ç±»ä¹‹åï¼‰ï¼š

```python
class MarkdownReportGenerator:
    """Markdown æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, output_dir):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            output_dir: str, è¾“å‡ºåŸºç¡€ç›®å½•
        """
        self.output_dir = output_dir

    def generate(self, date, projects, analyses, trend_summary):
        """
        ç”Ÿæˆ Markdown æŠ¥å‘Š

        Args:
            date: str, æ—¥æœŸ (YYYY-MM-DD)
            projects: list[dict], åŸå§‹é¡¹ç›®æ•°æ®
            analyses: dict, AI åˆ†æç»“æœ
            trend_summary: dict, è¶‹åŠ¿åˆ†æç»“æœ

        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        year = date.split('-')[0]
        output_path = os.path.join(self.output_dir, 'github-trending-ai-analysis', year)
        os.makedirs(output_path, exist_ok=True)

        filename = os.path.join(output_path, f'{date}.md')

        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        content = self._generate_content(date, projects, analyses, trend_summary)

        # å†™å…¥æ–‡ä»¶
        with codecs.open(filename, 'w', 'utf-8') as f:
            f.write(content)

        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        return filename

    def _generate_content(self, date, projects, analyses, trend_summary):
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        content = f"""# GitHub Trending æ¯æ—¥åˆ†ææŠ¥å‘Š - {date}

## ğŸ“ˆ ä»Šæ—¥è¶‹åŠ¿æ¦‚è§ˆ

{trend_summary.get('trend_overview', '')}

## ğŸ”¥ çƒ­é—¨é¢†åŸŸ

"""

        # çƒ­é—¨é¢†åŸŸ
        for domain in trend_summary.get('hot_domains', []):
            content += f"""### {domain.get('domain', 'æœªçŸ¥é¢†åŸŸ')}

{domain.get('reason', '')}

**ç›¸å…³é¡¹ç›®ï¼š** {', '.join(domain.get('projects', []))}

"""

        # é¡¹ç›®è¯¦æƒ…
        content += "\n## ğŸ“¦ é¡¹ç›®è¯¦æƒ…åˆ†æ\n\n"

        # åˆ›å»ºé¡¹ç›®åç§°åˆ°åˆ†æçš„æ˜ å°„
        analysis_map = {p['name']: p for p in analyses.get('projects', [])}

        for idx, project in enumerate(projects, 1):
            name = project['name']
            analysis = analysis_map.get(name, {})

            content += f"""### {idx}. [{name}]({project['url']})

**æ˜Ÿæ ‡ï¼š** {project['stars']} (ä»Šæ—¥ +{project['stars_today']}) | **è¯­è¨€ï¼š** {project['language']}

**æ ¸å¿ƒåŠŸèƒ½ï¼š** {analysis.get('core_functionality', 'æš‚æ— ')}

**é€‚ç”¨åœºæ™¯ï¼š**
{self._format_list(analysis.get('use_cases', ''))}

**æŠ€æœ¯æ ˆï¼š** {analysis.get('tech_stack', 'æœªçŸ¥')}

**æŠ€æœ¯äº®ç‚¹ï¼š**
{self._format_list(analysis.get('tech_highlights', ''))}

**å­¦ä¹ ä»·å€¼ï¼š** {analysis.get('learning_value', 'æš‚æ— ')}

---

"""

        return content

    def _format_list(self, text):
        """æ ¼å¼åŒ–åˆ—è¡¨æ–‡æœ¬"""
        if not text:
            return "- æš‚æ— "
        lines = text.strip().split('\n')
        return '\n'.join(f"- {line.strip()}" for line in lines if line.strip())
```

**æ­¥éª¤ 2: æµ‹è¯•æŠ¥å‘Šç”Ÿæˆç±»**

åœ¨ `if __name__ == '__main__':` éƒ¨åˆ†æ·»åŠ å®Œæ•´æµ‹è¯•ï¼š

```python
if __name__ == '__main__':
    # å®Œæ•´æµç¨‹æµ‹è¯•
    logger.info("å¼€å§‹ GitHub Trending AI åˆ†æ")

    # 1. çˆ¬å–æ•°æ®
    scraper = GitHubTrendingScraper()
    projects = scraper.scrape_all_languages()[:5]  # æµ‹è¯• 5 ä¸ª

    # 2. AI åˆ†æ
    analyzer = GLMAnalyzer()
    analyses = analyzer.analyze_projects(projects)

    # 3. è¶‹åŠ¿æ€»ç»“
    trend_summary = analyzer.generate_trend_summary(analyses)

    # 4. ç”ŸæˆæŠ¥å‘Š
    generator = MarkdownReportGenerator('output')
    date = datetime.datetime.now().strftime('%Y-%m-%d')
    report_path = generator.generate(date, projects, analyses, trend_summary)

    logger.info(f"åˆ†æå®Œæˆï¼æŠ¥å‘Šè·¯å¾„: {report_path}")
```

è¿è¡Œï¼š`BIGMODEL_API_KEY=your_key python script/github-trending-ai-analysis.py`

é¢„æœŸè¾“å‡ºï¼š
```
[2026-02-15 XX:XX:XX] INFO: å¼€å§‹ GitHub Trending AI åˆ†æ
[2026-02-15 XX:XX:XX] INFO: æ­£åœ¨çˆ¬å– GitHub Trending: https://github.com/trending
[2026-02-15 XX:XX:XX] INFO: æˆåŠŸçˆ¬å– 5 ä¸ªé¡¹ç›®
[2026-02-15 XX:XX:XX] INFO: æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• 1/3)
[2026-02-15 XX:XX:XX] INFO: API è°ƒç”¨æˆåŠŸ
[2026-02-15 XX:XX:XX] INFO: æˆåŠŸåˆ†æ 5 ä¸ªé¡¹ç›®
[2026-02-15 XX:XX:XX] INFO: æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• 1/3)
[2026-02-15 XX:XX:XX] INFO: API è°ƒç”¨æˆåŠŸ
[2026-02-15 XX:XX:XX] INFO: æˆåŠŸç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆ
[2026-02-15 XX:XX:XX] INFO: æŠ¥å‘Šå·²ä¿å­˜: output/github-trending-ai-analysis/2026/2026-02-15.md
[2026-02-15 XX:XX:XX] INFO: åˆ†æå®Œæˆï¼æŠ¥å‘Šè·¯å¾„: output/github-trending-ai-analysis/2026/2026-02-15.md
```

**æ­¥éª¤ 3: éªŒè¯æŠ¥å‘Šå†…å®¹**

æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šï¼š`cat output/github-trending-ai-analysis/2026/2026-02-15.md`

éªŒè¯æŠ¥å‘ŠåŒ…å«ï¼š
- æ ‡é¢˜å’Œæ—¥æœŸ
- è¶‹åŠ¿æ¦‚è§ˆéƒ¨åˆ†
- çƒ­é—¨é¢†åŸŸéƒ¨åˆ†
- é¡¹ç›®è¯¦æƒ…éƒ¨åˆ†ï¼ˆ5 ä¸ªé¡¹ç›®ï¼‰

**æ­¥éª¤ 4: æäº¤æŠ¥å‘Šç”Ÿæˆç±»**

```bash
git add script/github-trending-ai-analysis.py
git commit -m "feat: add markdown report generator class"
```

---

## Task 5: å®ç°ä¸»æµç¨‹ job() å‡½æ•°

**æ–‡ä»¶ï¼š**
- ä¿®æ”¹: `script/github-trending-ai-analysis.py`ï¼ˆæ·»åŠ  job() å‡½æ•°ï¼‰

**æ­¥éª¤ 1: å®ç° job() å‡½æ•°**

åœ¨æ–‡ä»¶ä¸­æ·»åŠ  job() å‡½æ•°ï¼ˆæ·»åŠ åˆ°æ‰€æœ‰ç±»å®šä¹‰ä¹‹åï¼Œ`if __name__` ä¹‹å‰ï¼‰ï¼š

```python
def job():
    """ä¸»ä»»åŠ¡å…¥å£"""
    start_time = time.time()
    logger.info("="*60)
    logger.info("GitHub Trending AI åˆ†æä»»åŠ¡å¼€å§‹")
    logger.info("="*60)

    try:
        # 1. è·å–å½“å‰æ—¥æœŸ
        date = datetime.datetime.now().strftime('%Y-%m-%d')
        logger.info(f"ç›®æ ‡æ—¥æœŸ: {date}")

        # 2. çˆ¬å– GitHub Trending æ•°æ®
        logger.info("æ­¥éª¤ 1/4: çˆ¬å– GitHub Trending æ•°æ®")
        scraper = GitHubTrendingScraper()
        projects = scraper.scrape_all_languages()

        if len(projects) == 0:
            logger.error("æœªçˆ¬å–åˆ°ä»»ä½•é¡¹ç›®ï¼Œä»»åŠ¡ç»ˆæ­¢")
            return

        logger.info(f"æˆåŠŸè·å– {len(projects)} ä¸ªé¡¹ç›®")

        # 3. AI æ‰¹é‡åˆ†æ
        logger.info("æ­¥éª¤ 2/4: AI æ‰¹é‡åˆ†æé¡¹ç›®")
        analyzer = GLMAnalyzer()
        analyses = analyzer.analyze_projects(projects)

        if len(analyses.get('projects', [])) == 0:
            logger.error("AI åˆ†æå¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢")
            return

        # 4. ç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆ
        logger.info("æ­¥éª¤ 3/4: ç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆå’Œçƒ­é—¨é¢†åŸŸ")
        trend_summary = analyzer.generate_trend_summary(analyses)

        # 5. ç”ŸæˆæŠ¥å‘Š
        logger.info("æ­¥éª¤ 4/4: ç”Ÿæˆ Markdown æŠ¥å‘Š")
        generator = MarkdownReportGenerator('output')
        report_path = generator.generate(date, projects, analyses, trend_summary)

        # 6. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        elapsed = time.time() - start_time
        logger.info("="*60)
        logger.info("ä»»åŠ¡å®Œæˆï¼")
        logger.info(f"æ‰§è¡Œæ—¶é—´: {elapsed:.2f} ç§’")
        logger.info(f"åˆ†æé¡¹ç›®æ•°: {len(projects)}")
        logger.info(f"æŠ¥å‘Šè·¯å¾„: {report_path}")
        logger.info("="*60)

    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
```

**æ­¥éª¤ 2: æ›´æ–° main å—æµ‹è¯•**

ä¿®æ”¹ `if __name__ == '__main__':` éƒ¨åˆ†ï¼š

```python
if __name__ == '__main__':
    job()
```

**æ­¥éª¤ 3: æµ‹è¯•å®Œæ•´æµç¨‹**

è¿è¡Œï¼š`BIGMODEL_API_KEY=your_key python script/github-trending-ai-analysis.py`

é¢„æœŸè¾“å‡ºï¼š
```
============================================================
GitHub Trending AI åˆ†æä»»åŠ¡å¼€å§‹
============================================================
ç›®æ ‡æ—¥æœŸ: 2026-02-15
æ­¥éª¤ 1/4: çˆ¬å– GitHub Trending æ•°æ®
æ­£åœ¨çˆ¬å– GitHub Trending: https://github.com/trending
æˆåŠŸçˆ¬å– 25 ä¸ªé¡¹ç›®
æˆåŠŸè·å– 25 ä¸ªé¡¹ç›®
æ­¥éª¤ 2/4: AI æ‰¹é‡åˆ†æé¡¹ç›®
æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• 1/3)
API è°ƒç”¨æˆåŠŸ
æˆåŠŸåˆ†æ 25 ä¸ªé¡¹ç›®
æ­¥éª¤ 3/4: ç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆå’Œçƒ­é—¨é¢†åŸŸ
æ­£åœ¨è°ƒ GLM-4.7 API (å°è¯• 1/3)
API è°ƒç”¨æˆåŠŸ
æˆåŠŸç”Ÿæˆè¶‹åŠ¿æ¦‚è§ˆ
æ­¥éª¤ 4/4: ç”Ÿæˆ Markdown æŠ¥å‘Š
æŠ¥å‘Šå·²ä¿å­˜: output/github-trending-ai-analysis/2026/2026-02-15.md
============================================================
ä»»åŠ¡å®Œæˆï¼
æ‰§è¡Œæ—¶é—´: XX.XX ç§’
åˆ†æé¡¹ç›®æ•°: 25
æŠ¥å‘Šè·¯å¾„: output/github-trending-ai-analysis/2026/2026-02-15.md
============================================================
```

**æ­¥éª¤ 4: æäº¤ä¸»æµç¨‹**

```bash
git add script/github-trending-ai-analysis.py
git commit -m "feat: implement main job function"
```

---

## Task 6: åˆ›å»º GitHub Actions Workflow

**æ–‡ä»¶ï¼š**
- åˆ›å»º: `.github/workflows/github-trending-ai-analysis.yml`

**æ­¥éª¤ 1: åˆ›å»º workflow é…ç½®**

åˆ›å»ºæ–‡ä»¶ `.github/workflows/github-trending-ai-analysis.yml`ï¼š

```yaml
name: GitHub Trending AI Analysis

on:
  schedule:
    - cron: "0 2 * * *"  # æ¯æ—¥ 00:00 UTC
  workflow_dispatch:  # æ”¯æŒæ‰‹åŠ¨è§¦å‘

jobs:
  analyze:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python 3.8
      uses: actions/setup-python@v2
      with:
        python-version: 3.8

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run AI analysis
      env:
        BIGMODEL_API_KEY: ${{ secrets.BIGMODEL_API_KEY }}
      run: |
        python script/github-trending-ai-analysis.py

    - name: Commit and push results
      run: |
        git config --global user.name "tinkerc"
        git config --global user.email "chenruoyun@126.com"
        git add -A
        git commit -m "feat: update trending AI analysis $(date '+%Y-%m-%d')" || echo "No changes to commit"
        git push
```

**æ­¥éª¤ 2: æäº¤ workflow**

```bash
git add .github/workflows/github-trending-ai-analysis.yml
git commit -m "feat: add GitHub Actions workflow for trending AI analysis"
```

---

## Task 7: éªŒè¯å’Œæµ‹è¯•

**æ­¥éª¤ 1: æœ¬åœ°å®Œæ•´æµ‹è¯•**

è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆ25 ä¸ªé¡¹ç›®ï¼‰ï¼š

```bash
BIGMODEL_API_KEY=your_key python script/github-trending-ai-analysis.py
```

éªŒè¯ï¼š
- æˆåŠŸçˆ¬å– 25 ä¸ªé¡¹ç›®
- AI åˆ†æè¿”å› 25 ä¸ªé¡¹ç›®åˆ†æ
- è¶‹åŠ¿æ¦‚è§ˆç”ŸæˆæˆåŠŸ
- æŠ¥å‘Šæ–‡ä»¶åŒ…å«æ‰€æœ‰å†…å®¹
- æ‰§è¡Œæ—¶é—´åˆç†ï¼ˆ< 5 åˆ†é’Ÿï¼‰

**æ­¥éª¤ 2: æ£€æŸ¥æŠ¥å‘Šè´¨é‡**

æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šï¼š

```bash
cat output/github-trending-ai-analysis/2026/$(date +%Y-%m-%d).md | head -100
```

éªŒè¯æŠ¥å‘Šè´¨é‡ï¼š
- æ ‡é¢˜æ ¼å¼æ­£ç¡®
- è¶‹åŠ¿æ¦‚è§ˆå†…å®¹æœ‰æ„ä¹‰
- çƒ­é—¨é¢†åŸŸåˆ†ç±»åˆç†ï¼ˆ3-5 ä¸ªé¢†åŸŸï¼‰
- æ¯ä¸ªé¡¹ç›®åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
- Markdown æ ¼å¼æ­£ç¡®

**æ­¥éª¤ 3: æµ‹è¯•é”™è¯¯å¤„ç†**

æµ‹è¯• API key æœªè®¾ç½®ï¼š

```bash
unset BIGMODEL_API_KEY
python script/github-trending-ai-analysis.py
```

é¢„æœŸè¾“å‡ºï¼š
```
ValueError: ç¯å¢ƒå˜é‡ BIGMODEL_API_KEY æœªè®¾ç½®
```

**æ­¥éª¤ 4: æäº¤æœ€ç»ˆç‰ˆæœ¬**

```bash
git add script/github-trending-ai-analysis.py script/prompts/trending_prompts.py
git commit -m "chore: add error handling and final polish"
```

---

## Task 8: æ›´æ–°é¡¹ç›®æ–‡æ¡£

**æ–‡ä»¶ï¼š**
- ä¿®æ”¹: `CLAUDE.md`

**æ­¥éª¤ 1: æ›´æ–° CLAUDE.md**

åœ¨ `CLAUDE.md` çš„ "Script Conventions" éƒ¨åˆ†æ·»åŠ ï¼š

```markdown
Scripts are executed in filename order:
- `1.ai-news.py` - Fetches AI news from https://ai-bot.cn/daily-ai-news/ and saves as JSON
- `2.wecom-robot.py` - Reads the news JSON and posts to WeChat Work webhook
- `github-trending.py` - Scrapes GitHub trending repositories for multiple languages
- `bigmodel-stream-official.py` - Makes API calls to ZhipuAI (GLM-4 model)
- `github-trending-ai-analysis.py` - Independent script for GitHub Trending AI analysis (uses GLM-4.7)
```

åœ¨ "Development Notes" éƒ¨åˆ†æ·»åŠ ï¼š

```markdown
- The `github-trending-ai-analysis.py` script runs independently via GitHub Actions workflow
- Output: `output/github-trending-ai-analysis/YYYY/YYYY-MM-DD.md`
- Requires `BIGMODEL_API_KEY` environment variable
```

**æ­¥éª¤ 2: æäº¤æ–‡æ¡£æ›´æ–°**

```bash
git add CLAUDE.md
git commit -m "docs: update CLAUDE.md with trending AI analysis info"
```

---

## Task 9: æ¨é€åˆ°è¿œç¨‹ä»“åº“

**æ­¥éª¤ 1: æ¨é€æ‰€æœ‰æäº¤**

```bash
git push origin main
```

**æ­¥éª¤ 2: éªŒè¯ GitHub Actions**

1. è®¿é—® GitHub Actions é¡µé¢
2. æŸ¥çœ‹ workflow "GitHub Trending AI Analysis"
3. ç¡®è®¤ secrets ä¸­é…ç½®äº† `BIGMODEL_API_KEY`
4. æ‰‹åŠ¨è§¦å‘ workflow æµ‹è¯•ï¼ˆworkflow_dispatchï¼‰

**æ­¥éª¤ 3: éªŒè¯è¾“å‡º**

ç­‰å¾… workflow å®Œæˆåï¼Œæ£€æŸ¥ä»“åº“ä¸­çš„ `output/github-trending-ai-analysis/` ç›®å½•ã€‚

---

## é™„å½•ï¼šé…ç½® Secrets

### GitHub Actions Secrets é…ç½®

åœ¨ GitHub ä»“åº“è®¾ç½®ä¸­æ·»åŠ  Secretï¼š
1. Settings â†’ Secrets and variables â†’ Actions
2. New repository secret
3. Name: `BIGMODEL_API_KEY`
4. Value: ä½ çš„ GLM-4.7 API å¯†é’¥
5. ç‚¹å‡» Add secret

---

## æµ‹è¯•æ¸…å•

- [ ] æœ¬åœ°è¿è¡ŒæˆåŠŸï¼ˆ5 ä¸ªé¡¹ç›®æµ‹è¯•ï¼‰
- [ ] æœ¬åœ°è¿è¡ŒæˆåŠŸï¼ˆ25 ä¸ªé¡¹ç›®å®Œæ•´æµç¨‹ï¼‰
- [ ] æŠ¥å‘Šå†…å®¹å®Œæ•´ä¸”æ ¼å¼æ­£ç¡®
- [ ] API key æœªè®¾ç½®æ—¶æ­£ç¡®æŠ¥é”™
- [ ] ç½‘ç»œé”™è¯¯æ—¶æ­£ç¡®é‡è¯•
- [ ] GitHub Actions workflow é…ç½®æ­£ç¡®
- [ ] æ‰‹åŠ¨è§¦å‘ workflow æˆåŠŸ
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ
